"""
Agent IA Autonome Principal
"""

import asyncio
import logging
from typing import Dict, List, Any, Optional
from datetime import datetime
import json

from openai import AsyncOpenAI
from anthropic import AsyncAnthropic

from .planner import TaskPlanner
from .memory import MemorySystem
from .executor import TaskExecutor
from tools import ToolRegistry

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class SintraAgent:
    """
    Agent IA autonome capable de planifier et ex√©cuter des t√¢ches complexes
    """
    
    def __init__(
        self,
        name: str = "Sintra",
        model: str = "gpt-4-turbo-preview",
        api_key: Optional[str] = None,
        anthropic_key: Optional[str] = None,
        max_iterations: int = 50,
        temperature: float = 0.7
    ):
        self.name = name
        self.model = model
        self.max_iterations = max_iterations
        self.temperature = temperature
        
        # Initialisation des clients API
        self.openai_client = AsyncOpenAI(api_key=api_key) if api_key else None
        self.anthropic_client = AsyncAnthropic(api_key=anthropic_key) if anthropic_key else None
        
        # Initialisation des composants
        self.planner = TaskPlanner(self)
        self.memory = MemorySystem()
        self.executor = TaskExecutor(self)
        self.tool_registry = ToolRegistry()
        
        # √âtat de l'agent
        self.current_task = None
        self.task_history = []
        self.is_running = False
        
        logger.info(f"Agent {self.name} initialis√© avec le mod√®le {self.model}")
    
    async def run_task(self, task_description: str, context: Optional[Dict] = None) -> Dict[str, Any]:
        """
        Ex√©cute une t√¢che de mani√®re autonome
        
        Args:
            task_description: Description de la t√¢che √† accomplir
            context: Contexte additionnel pour la t√¢che
            
        Returns:
            R√©sultat de l'ex√©cution de la t√¢che
        """
        if self.is_running:
            raise RuntimeError("L'agent est d√©j√† en cours d'ex√©cution d'une t√¢che")
        
        self.is_running = True
        self.current_task = {
            "description": task_description,
            "context": context or {},
            "start_time": datetime.now(),
            "status": "running"
        }
        
        try:
            logger.info(f"üöÄ D√©marrage de la t√¢che: {task_description}")
            
            # √âtape 1: Planification
            logger.info("üìã Phase de planification...")
            plan = await self.planner.create_plan(task_description, context)
            self.current_task["plan"] = plan
            
            # √âtape 2: Ex√©cution
            logger.info(f"‚öôÔ∏è  Ex√©cution du plan ({len(plan['steps'])} √©tapes)...")
            results = await self.executor.execute_plan(plan)
            
            # √âtape 3: Synth√®se
            logger.info("üìä Synth√®se des r√©sultats...")
            final_result = await self._synthesize_results(task_description, results)
            
            # Sauvegarder dans la m√©moire
            await self.memory.store_task(task_description, plan, results, final_result)
            
            self.current_task["status"] = "completed"
            self.current_task["end_time"] = datetime.now()
            self.current_task["result"] = final_result
            self.task_history.append(self.current_task)
            
            logger.info("‚úÖ T√¢che compl√©t√©e avec succ√®s!")
            
            return {
                "success": True,
                "result": final_result,
                "plan": plan,
                "execution_results": results,
                "duration": (self.current_task["end_time"] - self.current_task["start_time"]).total_seconds()
            }
            
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de l'ex√©cution: {str(e)}")
            self.current_task["status"] = "failed"
            self.current_task["error"] = str(e)
            self.current_task["end_time"] = datetime.now()
            
            return {
                "success": False,
                "error": str(e),
                "task": self.current_task
            }
        finally:
            self.is_running = False
            self.current_task = None
    
    async def think(self, prompt: str, context: Optional[Dict] = None) -> str:
        """
        Fait r√©fl√©chir l'agent avec un prompt donn√©
        
        Args:
            prompt: Le prompt √† envoyer au mod√®le
            context: Contexte additionnel
            
        Returns:
            La r√©ponse du mod√®le
        """
        # R√©cup√©rer la m√©moire pertinente
        relevant_memories = await self.memory.retrieve_relevant(prompt, limit=5)
        
        # Construire le prompt avec contexte
        full_prompt = self._build_prompt(prompt, context, relevant_memories)
        
        # Envoyer au mod√®le appropri√©
        if self.model.startswith("gpt"):
            return await self._openai_completion(full_prompt)
        elif self.model.startswith("claude"):
            return await self._anthropic_completion(full_prompt)
        else:
            raise ValueError(f"Mod√®le non support√©: {self.model}")
    
    def _build_prompt(
        self,
        prompt: str,
        context: Optional[Dict],
        memories: List[Dict]
    ) -> str:
        """Construit le prompt complet avec contexte et m√©moires"""
        
        system_prompt = f"""Tu es {self.name}, un agent IA autonome sophistiqu√©.

Tes capacit√©s:
- Planification et d√©composition de t√¢ches complexes
- Raisonnement logique et r√©solution de probl√®mes
- Utilisation d'outils (recherche web, ex√©cution de code, etc.)
- Apprentissage et adaptation

Outils disponibles:
{self._format_available_tools()}

Principes:
1. D√©compose les t√¢ches complexes en √©tapes simples
2. V√©rifie toujours tes r√©sultats
3. Apprends de tes exp√©riences pass√©es
4. Sois pr√©cis et m√©thodique
"""
        
        context_section = ""
        if context:
            context_section = f"\n\nContexte actuel:\n{json.dumps(context, indent=2)}"
        
        memory_section = ""
        if memories:
            memory_section = "\n\nExp√©riences pertinentes:\n"
            for mem in memories:
                memory_section += f"- {mem['description']}\n"
        
        return f"{system_prompt}{context_section}{memory_section}\n\nT√¢che:\n{prompt}"
    
    def _format_available_tools(self) -> str:
        """Formate la liste des outils disponibles"""
        tools = self.tool_registry.list_tools()
        return "\n".join([f"- {tool['name']}: {tool['description']}" for tool in tools])
    
    async def _openai_completion(self, prompt: str) -> str:
        """Obtient une compl√©tion via OpenAI"""
        if not self.openai_client:
            raise ValueError("Client OpenAI non initialis√©")
        
        response = await self.openai_client.chat.completions.create(
            model=self.model,
            messages=[
                {"role": "system", "content": "Tu es Sintra, un agent IA autonome."},
                {"role": "user", "content": prompt}
            ],
            temperature=self.temperature,
            max_tokens=4000
        )
        
        return response.choices[0].message.content
    
    async def _anthropic_completion(self, prompt: str) -> str:
        """Obtient une compl√©tion via Anthropic"""
        if not self.anthropic_client:
            raise ValueError("Client Anthropic non initialis√©")
        
        response = await self.anthropic_client.messages.create(
            model=self.model,
            max_tokens=4000,
            temperature=self.temperature,
            messages=[
                {"role": "user", "content": prompt}
            ]
        )
        
        return response.content[0].text
    
    async def _synthesize_results(
        self,
        task_description: str,
        execution_results: List[Dict]
    ) -> Dict[str, Any]:
        """
        Synth√©tise les r√©sultats d'ex√©cution en une r√©ponse finale
        """
        synthesis_prompt = f"""T√¢che originale: {task_description}

R√©sultats d'ex√©cution:
{json.dumps(execution_results, indent=2)}

Synth√©tise ces r√©sultats en une r√©ponse claire et compl√®te.
Format de r√©ponse (JSON):
{{
    "summary": "R√©sum√© de ce qui a √©t√© accompli",
    "key_findings": ["Point cl√© 1", "Point cl√© 2"],
    "data": {{}},  // Donn√©es structur√©es pertinentes
    "next_steps": ["Recommandation 1", "Recommandation 2"]
}}
"""
        
        response = await self.think(synthesis_prompt)
        
        try:
            # Tenter de parser en JSON
            return json.loads(response)
        except:
            # Si √©chec, retourner en format texte
            return {
                "summary": response,
                "raw_results": execution_results
            }
    
    def get_status(self) -> Dict[str, Any]:
        """Retourne le statut actuel de l'agent"""
        return {
            "name": self.name,
            "model": self.model,
            "is_running": self.is_running,
            "current_task": self.current_task,
            "tasks_completed": len(self.task_history),
            "memory_size": self.memory.size()
        }
    
    async def reset(self):
        """R√©initialise l'agent"""
        self.current_task = None
        self.task_history = []
        self.is_running = False
        await self.memory.clear()
        logger.info(f"Agent {self.name} r√©initialis√©")

