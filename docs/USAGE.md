# Guide d'utilisation - Sintra AI

## Introduction

Sintra AI est un agent IA autonome qui peut comprendre, planifier et ex√©cuter des t√¢ches complexes pour vous.

## D√©marrage rapide

### 1. Lancer le syst√®me

**Backend:**
```bash
python main.py
```

**Frontend:**
```bash
cd frontend
npm run dev
```

### 2. Acc√©der √† l'interface

Ouvrez http://localhost:3000 dans votre navigateur.

## Interface utilisateur

### Page d'accueil

L'interface principale se compose de trois onglets:

#### üìã T√¢ches

C'est ici que vous cr√©ez et suivez vos t√¢ches.

**Cr√©er une t√¢che:**
1. Tapez votre demande dans le champ de texte
2. Cliquez sur "üöÄ Lancer la t√¢che"
3. L'agent commence imm√©diatement √† travailler

**Exemples de t√¢ches:**
- "Recherche les derni√®res tendances en IA"
- "Calcule la somme de 123 + 456 et multiplie le r√©sultat par 2"
- "Cr√©e un plan d'apprentissage pour Python"
- "Analyse les avantages de TypeScript par rapport √† JavaScript"

**Suivre une t√¢che:**
- L'√©tat s'actualise automatiquement toutes les 5 secondes
- Les t√¢ches passent par les √©tats: En attente ‚Üí En cours ‚Üí Termin√©e/√âchou√©e

#### üß† M√©moire

Visualisez ce dont l'agent se souvient.

**Statistiques:**
- M√©moire de travail: Contexte actuel
- M√©moire √©pisodique: T√¢ches pass√©es
- M√©moire s√©mantique: Connaissances apprises

**Recherche:**
- Tapez une requ√™te pour chercher dans la m√©moire
- L'agent trouve les souvenirs pertinents

#### ‚ÑπÔ∏è √Ä propos

Informations sur le syst√®me et ses capacit√©s.

## Utilisation de l'API

### Python

```python
import requests
import time

API_BASE = "http://localhost:8000/api"

# Cr√©er une t√¢che
response = requests.post(f"{API_BASE}/tasks", json={
    "description": "Recherche sur l'intelligence artificielle",
    "autonomous": True
})

task_id = response.json()["task_id"]
print(f"T√¢che cr√©√©e: {task_id}")

# Attendre la compl√©tion
while True:
    status = requests.get(f"{API_BASE}/tasks/{task_id}").json()
    
    if status["status"] == "completed":
        print("‚úÖ T√¢che termin√©e!")
        print("R√©sultat:", status["result"])
        break
    elif status["status"] == "failed":
        print("‚ùå T√¢che √©chou√©e:", status.get("error"))
        break
    else:
        print("‚è≥ En cours...")
        time.sleep(3)
```

### JavaScript/TypeScript

```javascript
const API_BASE = "http://localhost:8000/api";

async function runTask(description) {
  // Cr√©er la t√¢che
  const createRes = await fetch(`${API_BASE}/tasks`, {
    method: "POST",
    headers: { "Content-Type": "application/json" },
    body: JSON.stringify({
      description,
      autonomous: true
    })
  });
  
  const { task_id } = await createRes.json();
  console.log(`T√¢che cr√©√©e: ${task_id}`);
  
  // Polling du statut
  while (true) {
    const statusRes = await fetch(`${API_BASE}/tasks/${task_id}`);
    const status = await statusRes.json();
    
    if (status.status === "completed") {
      console.log("‚úÖ Termin√©e!", status.result);
      return status.result;
    } else if (status.status === "failed") {
      console.error("‚ùå √âchou√©e:", status.error);
      throw new Error(status.error);
    }
    
    await new Promise(resolve => setTimeout(resolve, 3000));
  }
}

// Utilisation
runTask("Explique-moi l'apprentissage par renforcement");
```

### cURL

```bash
# Cr√©er une t√¢che
curl -X POST http://localhost:8000/api/tasks \
  -H "Content-Type: application/json" \
  -d '{
    "description": "Calcule 15 * 27 + 100",
    "autonomous": true
  }'

# R√©cup√©rer le statut
curl http://localhost:8000/api/tasks/task_1_20241023120000

# Faire r√©fl√©chir l'agent
curl -X POST http://localhost:8000/api/think \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "Quelle est la diff√©rence entre ML et DL ?"
  }'
```

## Types de t√¢ches support√©es

### 1. Recherche d'information

```
"Recherche des informations sur [sujet]"
"Trouve les derni√®res nouvelles sur [topic]"
"Quelles sont les tendances de [domaine] ?"
```

### 2. Calculs

```
"Calcule 123 + 456 * 2"
"Quelle est la racine carr√©e de 144 ?"
"Convertis 100 USD en EUR"
```

### 3. Analyse

```
"Analyse les avantages et inconv√©nients de [technologie]"
"Compare [A] et [B]"
"Quelles sont les implications de [√©v√©nement] ?"
```

### 4. Planification

```
"Cr√©e un plan pour apprendre [comp√©tence]"
"Organise un projet de [type]"
"Planifie un itin√©raire pour [destination]"
```

### 5. G√©n√©ration de contenu

```
"√âcris un article sur [sujet]"
"G√©n√®re des id√©es pour [projet]"
"Cr√©e un r√©sum√© de [texte]"
```

### 6. Programmation

```
"√âcris un script Python pour [t√¢che]"
"Debug ce code: [code]"
"Explique comment fonctionne [concept de programmation]"
```

## Bonnes pratiques

### 1. Soyez sp√©cifique

‚ùå **Mauvais:** "Recherche sur l'IA"
‚úÖ **Bon:** "Recherche les applications pratiques de l'IA en m√©decine en 2024"

### 2. D√©composez les t√¢ches complexes

‚ùå **Mauvais:** "Cr√©e-moi une entreprise compl√®te"
‚úÖ **Bon:** 
- T√¢che 1: "G√©n√®re des id√©es de startup en tech"
- T√¢che 2: "Analyse le march√© pour [id√©e choisie]"
- T√¢che 3: "Cr√©e un business plan pour [id√©e]"

### 3. Fournissez du contexte

‚ùå **Mauvais:** "Analyse ce document"
‚úÖ **Bon:** "Analyse ce document de sp√©cifications techniques pour identifier les risques potentiels et les recommandations d'am√©lioration"

### 4. Utilisez les exemples

L'interface propose des exemples de t√¢ches. Cliquez dessus pour les utiliser comme point de d√©part.

### 5. Surveillez la m√©moire

L'agent apprend de ses exp√©riences. Consultez l'onglet M√©moire pour voir ce qu'il a retenu.

## Mode d√©monstration

Pour tester rapidement l'agent sans l'interface:

```bash
python main.py demo
```

Cela ex√©cute une t√¢che de d√©monstration pr√©d√©finie.

## Configuration avanc√©e

### Changer le mod√®le d'IA

Dans `.env`:
```env
# OpenAI
AGENT_MODEL=gpt-4-turbo-preview
# ou
AGENT_MODEL=gpt-3.5-turbo

# Anthropic
AGENT_MODEL=claude-3-opus-20240229
# ou
AGENT_MODEL=claude-3-sonnet-20240229
```

### Ajuster la temp√©rature

Plus √©lev√©e = Plus cr√©atif, moins pr√©visible
Plus basse = Plus d√©terministe, plus coh√©rent

```env
TEMPERATURE=0.7  # Par d√©faut
# 0.0 = tr√®s d√©terministe
# 1.0 = tr√®s cr√©atif
```

### Limites

```env
MAX_ITERATIONS=50          # Nombre max d'it√©rations
MAX_TASK_DURATION=3600     # Timeout en secondes
MAX_CONCURRENT_TASKS=5     # T√¢ches simultan√©es
```

## R√©solution de probl√®mes

### L'agent ne r√©pond pas

1. V√©rifiez que le backend est lanc√©
2. V√©rifiez votre cl√© API
3. Consultez les logs dans le terminal

### T√¢che √©choue imm√©diatement

1. La t√¢che est peut-√™tre trop vague
2. V√©rifiez les logs pour l'erreur exacte
3. R√©essayez avec plus de contexte

### R√©sultats incoh√©rents

1. Augmentez le nombre d'it√©rations
2. Baissez la temp√©rature
3. Soyez plus sp√©cifique dans votre demande

### Performance lente

1. V√©rifiez votre connexion internet
2. Certaines t√¢ches prennent naturellement plus de temps
3. Envisagez un mod√®le plus rapide (gpt-3.5-turbo)

## Exemples d'utilisation avanc√©e

### Cha√Æner des t√¢ches

```python
# T√¢che 1: Recherche
task1 = create_task("Recherche les frameworks JS populaires en 2024")
result1 = wait_for_task(task1)

# T√¢che 2: Analyse bas√©e sur les r√©sultats
frameworks = extract_frameworks(result1)
task2 = create_task(f"Compare {frameworks[0]} et {frameworks[1]}")
result2 = wait_for_task(task2)

# T√¢che 3: Recommandation
task3 = create_task(f"Recommande le meilleur framework pour un projet {project_type} bas√© sur l'analyse pr√©c√©dente")
result3 = wait_for_task(task3)
```

### Int√©gration dans une application

```python
from sintra_client import SintraClient

client = SintraClient("http://localhost:8000/api")

# Dans votre application
@app.route('/analyze', methods=['POST'])
def analyze():
    data = request.json
    
    # Utiliser Sintra pour l'analyse
    result = client.run_task(
        f"Analyse ces donn√©es: {data}"
    )
    
    return jsonify(result)
```

## Limites actuelles

1. **Code ex√©cution**: Sandbox basique (pas de Docker)
2. **Recherche web**: Simul√©e (pas de vraie API)
3. **M√©moire**: En RAM (pas de persistance)
4. **Multi-utilisateurs**: Non support√©
5. **Streaming**: Pas de r√©ponses en streaming

Ces limitations seront adress√©es dans les versions futures.

## Support

- Documentation: `/docs`
- API interactive: http://localhost:8000/docs
- Issues: GitHub (si open source)

## Prochaines √©tapes

1. Explorez les diff√©rents types de t√¢ches
2. Testez l'API dans vos projets
3. Exp√©rimentez avec diff√©rents mod√®les
4. Consultez la documentation avanc√©e dans `/docs`

